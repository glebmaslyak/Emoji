{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Model_1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Model_2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever wanted to make your text messages more expressive? Your emojifier app will help you do that. So rather than writing \"Congratulations on the promotion! Lets get coffee and talk. Love you!\" the emojifier can automatically turn this into \"Congratulations on the promotion! üëç Lets get coffee and talk. ‚òïÔ∏è Love you! ‚ù§Ô∏è\"\n",
    "\n",
    "Two models are implemented. They input a sentence (such as \"Let's go see the baseball game tonight!\") and find the most appropriate emoji to be used with this sentence (‚öæÔ∏è)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset EMOJISET\n",
    "\n",
    "- X contains 127 sentences (strings)\n",
    "- Y contains a integer label between 0 and 4 corresponding to an emoji for each sentence\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> \n",
    "Let's load the dataset using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÑ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0], label_to_emoji(Y_train[0]))\n",
    "print(X_train[1], label_to_emoji(Y_train[1]))\n",
    "print(X_train[2], label_to_emoji(Y_train[2]))\n",
    "print(X_train[3], label_to_emoji(Y_train[3]))\n",
    "print(X_train[4], label_to_emoji(Y_train[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-1\n",
    "\n",
    "<center>\n",
    "<img src=\"images/emojifierv1.png\" style=\"width:900px;height:300px;\">\n",
    "<caption><center> \n",
    "</center>\n",
    "\n",
    "The input of the model is a string corresponding to a sentence (e.g. \"I love you). In the code, the output is a probability vector of shape (1,5), that is passed in an argmax layer to extract the index of the most likely emoji output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.88342378571\n",
      "Accuracy: 0.318181818182\n",
      "Epoch: 100 --- cost = 0.0699891210417\n",
      "Accuracy: 0.931818181818\n",
      "Epoch: 200 --- cost = 0.0418992146179\n",
      "Accuracy: 0.954545454545\n",
      "Epoch: 300 --- cost = 0.0334994286393\n",
      "Accuracy: 0.969696969697\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.977272727273\n",
      "Test set:\n",
      "Accuracy: 0.892857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.833333333333\n",
      "\n",
      "i adore you ‚ù§Ô∏è\n",
      "i love you ‚ù§Ô∏è\n",
      "funny lol üòÑ\n",
      "lets play with a ball ‚öæ\n",
      "food is ready üç¥\n",
      "not feeling happy üòÑ\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           ‚ù§Ô∏è    ‚öæ    üòÑ    üòû   üç¥\n",
      "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
      "Actual                                 \n",
      "0            6    0    0    1    0    7\n",
      "1            0    8    0    0    0    8\n",
      "2            1    0   17    0    0   18\n",
      "3            1    1    2   12    0   16\n",
      "4            0    0    0    0    7    7\n",
      "All          8    9   19   13    7   56\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD3CAYAAADormr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a20629518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Model-2: LSTM: \n",
    "\n",
    "This model is able to take word ordering into account. Model_2 also uses pre-trained word embeddings to represent words, but feeds them into an LSTM, whose job is to predict the most appropriate emoji. \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_lstm((maxLen,), word_to_vec_map, word_to_index, prob1=0.2, prob2=0.3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 3s 25ms/step - loss: 1.5730 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 1.4232 - acc: 0.4091\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 1.2200 - acc: 0.5076\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 1.0349 - acc: 0.5379\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.8065 - acc: 0.7197\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.7639 - acc: 0.6970\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.6139 - acc: 0.7576\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.5594 - acc: 0.7955\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.4047 - acc: 0.8636\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.3182 - acc: 0.8864\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.3833 - acc: 0.8788\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.2572 - acc: 0.9091\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.2786 - acc: 0.9091\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.2399 - acc: 0.9015\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.1815 - acc: 0.9318\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.1752 - acc: 0.9545\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.2457 - acc: 0.8939\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.2874 - acc: 0.8864\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.1512 - acc: 0.9470\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0862 - acc: 0.9848\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.1372 - acc: 0.9470\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.0908 - acc: 0.9848\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0746 - acc: 0.9621\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.1422 - acc: 0.9470\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0851 - acc: 0.9697\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0376 - acc: 0.9848\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0289 - acc: 0.9924\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 0.0316 - acc: 0.9848\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0615 - acc: 0.9924\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0218 - acc: 0.9924\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.0995 - acc: 0.9848\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0657 - acc: 0.9924\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0193 - acc: 0.9924\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 7.8936e-04 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 8.0927e-04 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 7.4730e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a794de710>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 1s 12ms/step\n",
      "\n",
      "Test accuracy =  0.892857142857\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:üòÑ prediction: he got a very nice raise\t‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: she got me a nice present\t‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: This girl is messing with me\t‚ù§Ô∏è\n",
      "Expected emoji:‚ù§Ô∏è prediction: I love taking breaks\tüòû\n",
      "Expected emoji:üòÑ prediction: you brighten my day\t‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: she is a bully\t‚ù§Ô∏è\n"
     ]
    }
   ],
   "source": [
    "C = 5\n",
    "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you ‚ù§Ô∏è\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['I love you'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy üòÑ\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['I am happy'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sad üòû\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['I am sad'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat üç¥\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['I want to eat'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like to play football ‚öæ\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['I like to play football'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://www.kaggle.com/devjyotichandra/glove6b50dtxt/downloads/glove.6B.50d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-f7dfc73815cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_to_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_vec_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_glove_vecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.kaggle.com/devjyotichandra/glove6b50dtxt/downloads/glove.6B.50d.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/admin/Downloads/Emoji_Classifier/emo_utils.py\u001b[0m in \u001b[0;36mread_glove_vecs\u001b[0;34m(glove_file)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_glove_vecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mword_to_vec_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.kaggle.com/devjyotichandra/glove6b50dtxt/downloads/glove.6B.50d.txt'"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('https://www.kaggle.com/devjyotichandra/glove6b50dtxt/downloads/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
